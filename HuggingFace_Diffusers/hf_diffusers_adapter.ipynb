{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 31 11:46:47 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.58.02              Driver Version: 555.58.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off |   00000000:49:00.0 Off |                  N/A |\n",
      "| 32%   31C    P8             25W /  420W |   16987MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        Off |   00000000:4F:00.0 Off |                  N/A |\n",
      "| 33%   30C    P8             21W /  420W |   12947MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6270      C   /usr/lib/python-exec/python3.10/python       1874MiB |\n",
      "|    0   N/A  N/A      6701      C   /usr/lib/python-exec/python3.10/python       3514MiB |\n",
      "|    0   N/A  N/A    109098      C   ...L/llama.cpp/build2/bin/llama-server      11580MiB |\n",
      "|    1   N/A  N/A    109098      C   ...L/llama.cpp/build2/bin/llama-server      12938MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stable models\n",
    "\n",
    "| models              | versions| Date | features | pretrained |\n",
    "| --------            | ------- | -----| ------- | ------- |\n",
    "| stable diffusion 1  | 1.1-1.5 | 6/22 | text: ViT-L/14 CLIP model<br>resolution: 77toks, 512X512<br>parameters: ~860M<br>quality: general usage, flat-looking | runwayml/stable-diffusion-v1-5 |\n",
    "| stable diffusion 2  | 2.0 2.1 | 11/22| text: ViT-H/14 CLIP model<br>resolution: 77toks, 768X768<br>parameters: ~860M<br>quality: general usage, flat-looking | stabilityai/stable-diffusion-2-1 |\n",
    "| stable diffusion XL | 1.0     | 6/23 | text: OpenCLIP-ViT model<br>resolution: 77toks, 1024X1024<br>parameters: ~3.5B<br>quality: general usage, high-res | stable-diffusion-xl-base-1.0 |\n",
    "| stable diffusion XL turbo |   | 11/23| text: OpenCLIP-ViT model<br>resolution: 77toks, 512X512<br>parameters: ~3.5B<br>quality: general usage, high-res | stabilityai/sdxl-turbo |\n",
    "| stable cascade      |         | 2/24 | Würstchen architecture - research only| stabilityai/stable-cascade |\n",
    "| stable diffusion 3  | 3.0 3.5 | 3/24 |  | stabilityai/stable-diffusion-3-medium-diffusers |\n",
    "| kandinsky           |         |      |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref:\n",
    "- Würstchen architecture: https://openreview.net/pdf?id=gU58d5QeGv\n",
    "- Comparing Stable Diffusion Models: https://medium.com/@promptingpixels/comparing-stable-diffusion-models-2c1dc9919ab7\n",
    "- Survey Conditional Image Synthesis with Diffusion Models: https://arxiv.org/pdf/2409.19365\n",
    "- controlnet: https://arxiv.org/pdf/2302.05543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9339aa2dc84125999a143d409c7fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956b1ac22668460c919fe46132dfc14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import AutoPipelineForImage2Image\n",
    "import torch\n",
    "pipe = AutoPipelineForImage2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\", use_safetensors=True, torch_dtype=torch.float16, variant=\"fp16\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859520964"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = sum([l.numel() for l in pipe.unet.parameters()])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_t = max(1, t.item() - (1000//num_inference_steps)) # t-1\n",
    "alpha_t = pipe.scheduler.alphas_cumprod[t.item()]\n",
    "alpha_t_prev = pipe.scheduler.alphas_cumprod[prev_t]\n",
    "predicted_x0 = (latents - (1-alpha_t).sqrt()*noise_pred) / alpha_t.sqrt()\n",
    "direction_pointing_to_xt = (1-alpha_t_prev).sqrt()*noise_pred\n",
    "latents = alpha_t_prev.sqrt()*predicted_x0 + direction_pointing_to_xt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser",
   "language": "python",
   "name": "diffuser"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
