{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prefix Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For prefix tuning, the prompt was cancatenated to the key and value of the attention blocs instead of the embedding bloc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformers > 4.34\n",
    "peft > 0.5\n",
    "accelerate > 0.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # or \"0,1\" for multiple GPUs\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 15:46:18.422939: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-25 15:46:18.423006: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-25 15:46:18.425233: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-25 15:46:18.436381: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 15:46:20.522352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# prepare task, we use the same example as butfit\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "\n",
    "ckp_data = \"yahma/alpaca-cleaned\"\n",
    "ckp = \"bigscience/bloomz-1b1\"\n",
    "\n",
    "# load dataset\n",
    "data = load_dataset(ckp_data, split=\"train[:1000]\")\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckp)\n",
    "\n",
    "# process data\n",
    "def process(sample):\n",
    "\n",
    "    MAX_LEN = 256\n",
    "\n",
    "    human = tokenizer(\"Human: \" + \"\\n\".join([sample[\"instruction\"], sample[\"input\"]]).strip() + \"\\n\\nAssistant: \")\n",
    "    ml = tokenizer(sample[\"output\"] + tokenizer.eos_token)\n",
    "\n",
    "    input_ids = human[\"input_ids\"] + ml[\"input_ids\"]\n",
    "    attention_mask = human[\"attention_mask\"] + ml[\"attention_mask\"]\n",
    "    labels = [-100] * len(human[\"input_ids\"]) + ml[\"input_ids\"]\n",
    "\n",
    "    if len(input_ids) > MAX_LEN:\n",
    "\n",
    "        input_ids = input_ids[:MAX_LEN]\n",
    "        attention_mask = attention_mask[:MAX_LEN]\n",
    "        labels = labels[:MAX_LEN]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# tokenize dataset\n",
    "tokenized_data = data.map(process, remove_columns=data.column_names)\n",
    "\n",
    "# load model\n",
    "model = AutoModelForCausalLM.from_pretrained(ckp, low_cpu_mem_usage=True)\n",
    "\n",
    "# send to device\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size:  1.065314304 GB\n",
      "total required memory:  21.31 GB\n"
     ]
    }
   ],
   "source": [
    "# compute model size\n",
    "\n",
    "params = sum(param.numel() for param in model.parameters())\n",
    "print(\"model size: \", params/1e9, \"GB\")\n",
    "print(\"total required memory: \", round(params/1e9 * (4 + 4 + 12), 2), \"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. prefix training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use prefix tuning, but we don't add project layer for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrefixTuningConfig(peft_type=<PeftType.PREFIX_TUNING: 'PREFIX_TUNING'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, num_virtual_tokens=10, token_dim=None, num_transformer_submodules=None, num_attention_heads=None, num_layers=None, encoder_hidden_size=None, prefix_projection=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we disable prefix project, which is similar to the soft prompt tuning\n",
    "# We can remember that the soft prompt tuning has very limited capacity to influence the result.\n",
    "# But with some projection layers, its performance can be improved, but with more trainable parameters.\n",
    "\n",
    "from peft import PrefixTuningConfig, get_peft_model, TaskType\n",
    "\n",
    "config = PrefixTuningConfig(task_type=TaskType.CAUSAL_LM, num_virtual_tokens=10, prefix_projection=False)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): BloomForCausalLM(\n",
       "    (transformer): BloomModel(\n",
       "      (word_embeddings): Embedding(250880, 1536)\n",
       "      (word_embeddings_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (h): ModuleList(\n",
       "        (0-23): 24 x BloomBlock(\n",
       "          (input_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attention): BloomAttention(\n",
       "            (query_key_value): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (post_attention_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BloomMLP(\n",
       "            (dense_h_to_4h): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (gelu_impl): BloomGelu()\n",
       "            (dense_4h_to_h): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1536, out_features=250880, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PrefixEncoder(\n",
       "      (embedding): Embedding(10, 1536)\n",
       "      (transform): Sequential(\n",
       "        (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (1): Tanh()\n",
       "        (2): Linear(in_features=1536, out_features=73728, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(250880, 1536)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, config)\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 737,280 || all params: 1,066,051,584 || trainable%: 0.0692\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 05:42, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.660200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.955900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.790800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=2.0014372965494793, metrics={'train_runtime': 343.5229, 'train_samples_per_second': 8.733, 'train_steps_per_second': 1.092, 'total_flos': 1670056200806400.0, 'train_loss': 2.0014372965494793, 'epoch': 3.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compared to prompt tuning, the training is much slower since the trainable parameters are greater\n",
    "# but the loss decreases more too.\n",
    "\n",
    "# define training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./checkpoint\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_data,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: List five steps for comparing two products.\n",
      "None\n",
      "\n",
      "Assistant: 1. Compare the two products by their brand name. 2. Compare the two products by their packaging. 3. Compare the two products by their ingredients. 4. Compare the two products by their packaging. 5. Compare the two products by their ingredients.\n"
     ]
    }
   ],
   "source": [
    "# even though the loss (previous cell) decrease, the inference gives no-meaningful results.\n",
    "# This may du to the fact that there are not enough training steps. With more training loop, the result\n",
    "# may improve but it is very slow.\n",
    "\n",
    "def generate(_model, _tokenizer, instruction, input=None):\n",
    "\n",
    "    prompt = \"human: {}\\n{}\".format(instruction, input).strip() + \"\\n\\nAssistant: \"\n",
    "    inputs = _tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(_model.device)\n",
    "\n",
    "    generation_output = _model.generate(\n",
    "        input_ids=input_ids,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "    for seq in generation_output:\n",
    "        output = tokenizer.decode(seq, skip_special_tokens=True)\n",
    "        print(output)\n",
    "\n",
    "generate(peft_model, tokenizer, \"List five steps for comparing two products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Projection layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In P-Tuning, we saw that by adding a projection layer to the soft prompt layer, the results improved. Here, we share the same idea by adding a projection layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrefixTuningConfig(peft_type=<PeftType.PREFIX_TUNING: 'PREFIX_TUNING'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, num_virtual_tokens=10, token_dim=None, num_transformer_submodules=None, num_attention_heads=None, num_layers=None, encoder_hidden_size=None, prefix_projection=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = PrefixTuningConfig(task_type=TaskType.CAUSAL_LM, num_virtual_tokens=10, prefix_projection=True)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 115,696,128 || all params: 1,181,010,432 || trainable%: 9.7964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): BloomForCausalLM(\n",
       "    (transformer): BloomModel(\n",
       "      (word_embeddings): Embedding(250880, 1536)\n",
       "      (word_embeddings_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      (h): ModuleList(\n",
       "        (0-23): 24 x BloomBlock(\n",
       "          (input_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (self_attention): BloomAttention(\n",
       "            (query_key_value): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (post_attention_layernorm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BloomMLP(\n",
       "            (dense_h_to_4h): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (gelu_impl): BloomGelu()\n",
       "            (dense_4h_to_h): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1536, out_features=250880, bias=False)\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PrefixEncoder(\n",
       "      (embedding): Embedding(10, 1536)\n",
       "      (transform): Sequential(\n",
       "        (0): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (1): Tanh()\n",
       "        (2): Linear(in_features=1536, out_features=73728, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(250880, 1536)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compared to when there is no projection layer, there are much more trainable parameters.\n",
    "\n",
    "peft_model.print_trainable_parameters()\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 115,696,128 || all params: 1,181,010,432 || trainable%: 9.7964\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 05:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.660200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.955900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.845200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.790800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=2.0014372965494793, metrics={'train_runtime': 334.7345, 'train_samples_per_second': 8.962, 'train_steps_per_second': 1.12, 'total_flos': 1670056200806400.0, 'train_loss': 2.0014372965494793, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./checkpoint\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_data,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: List five steps for comparing two products.\n",
      "None\n",
      "\n",
      "Assistant: 1. Compare the ingredients of the two products. 2. Compare the active ingredients. 3. Compare the dosages of the two products. 4. Compare the claims of the two products. 5. Compare their reviews.\n"
     ]
    }
   ],
   "source": [
    "# compared to when there is no project layers, the results make much more sens now.\n",
    "# The loss decreases significantly\n",
    "\n",
    "generate(peft_model, tokenizer, \"List five steps for comparing two products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the projection layer, the trainable parameters increase a lot, but the training loss decreased as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser",
   "language": "python",
   "name": "diffuser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
