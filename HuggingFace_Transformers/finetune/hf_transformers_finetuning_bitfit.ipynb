{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bitfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Presentation\n",
    "\n",
    "Bitfit is one of the technique to do finetuning but only update part of the parameters, namely the bias only.\n",
    "In other words, the weights of the layers are kept unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the the conversational example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # or \"0,1\" for multiple GPUs\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-23 16:30:29.495059: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-23 16:30:29.495221: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-23 16:30:29.584726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-23 16:30:29.737948: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-23 16:30:32.933385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ce7151399e41cf9540b4cdedc8a784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 03:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.397800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.361500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.242600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.379200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.944600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.049300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=2.1997402267456057, metrics={'train_runtime': 198.2195, 'train_samples_per_second': 5.045, 'train_steps_per_second': 0.631, 'total_flos': 556685400268800.0, 'train_loss': 2.1997402267456057, 'epoch': 1.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the example\n",
    "# For sake of illustrating finetuning, we don't do data split and don't do evaluations during training.\n",
    "\n",
    "\n",
    "# import\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "\n",
    "ckp_data = \"yahma/alpaca-cleaned\"\n",
    "ckp = \"bigscience/bloomz-1b1\"\n",
    "\n",
    "# load dataset\n",
    "data = load_dataset(ckp_data, split=\"train[:1000]\")\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckp)\n",
    "\n",
    "# process data\n",
    "def process(sample):\n",
    "\n",
    "    MAX_LEN = 256\n",
    "\n",
    "    human = tokenizer(\"Human: \" + \"\\n\".join([sample[\"instruction\"], sample[\"input\"]]).strip() + \"\\n\\nAssistant: \")\n",
    "    ml = tokenizer(sample[\"output\"] + tokenizer.eos_token)\n",
    "\n",
    "    input_ids = human[\"input_ids\"] + ml[\"input_ids\"]\n",
    "    attention_mask = human[\"attention_mask\"] + ml[\"attention_mask\"]\n",
    "    labels = [-100] * len(human[\"input_ids\"]) + ml[\"input_ids\"]\n",
    "\n",
    "    if len(input_ids) > MAX_LEN:\n",
    "\n",
    "        input_ids = input_ids[:MAX_LEN]\n",
    "        attention_mask = attention_mask[:MAX_LEN]\n",
    "        labels = labels[:MAX_LEN]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# tokenize dataset\n",
    "tokenized_data = data.map(process, remove_columns=data.column_names)\n",
    "\n",
    "# load model\n",
    "model = AutoModelForCausalLM.from_pretrained(ckp, low_cpu_mem_usage=True)\n",
    "\n",
    "# define training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"../tmp/checkpoint\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size:  1.065314304 GB\n",
      "total required memory:  21.31 GB\n"
     ]
    }
   ],
   "source": [
    "# compute model size\n",
    "\n",
    "params = sum(param.numel() for param in model.parameters())\n",
    "print(\"model size: \", params/1e9, \"GB\")\n",
    "print(\"total required memory: \", round(params/1e9 * (4 + 4 + 12), 2), \"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While running the training, it can be seen that we use 21Gb of momery over 24GB (my GPU has 24GB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. use bitfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update parameters:  408576 over total of:  1065314304  ( 0.0384 %)\n"
     ]
    }
   ],
   "source": [
    "# We freeze all weights in the model\n",
    "\n",
    "# we can see that the updated parameters reduced a lot\n",
    "\n",
    "params_count = 0\n",
    "total_count = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "\n",
    "    if \"bias\" not in name:\n",
    "        # if the parameter is not bias, freeze it\n",
    "        # and we count the parameter numbers \n",
    "        param.requires_grad = False\n",
    "        total_count += param.numel()\n",
    "    else:\n",
    "        # if the parameter is bias, count the number\n",
    "        # also update the total number of parameters\n",
    "        params_count += param.numel()\n",
    "        total_count += param.numel()\n",
    "\n",
    "print(\"update parameters: \", params_count, \"over total of: \", total_count, \" (\", round(params_count/total_count*100, 4), \"%)\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.866900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.926600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.904700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.726800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=1.118237762451172, metrics={'train_runtime': 106.3603, 'train_samples_per_second': 9.402, 'train_steps_per_second': 1.175, 'total_flos': 556685400268800.0, 'train_loss': 1.118237762451172, 'epoch': 1.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetuning only the bias\n",
    "\n",
    "# it cna be seen that the training is much faster\n",
    "\n",
    "# define training arguments\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"../tmp/checkpoint\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=1\n",
    ")\n",
    "\n",
    "# define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it uses < 6GB for training compared to 21 GB previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'human: List five steps for comparing two products.\\n\\nAssistant: 1. Identify the main difference between the two products\\n2. Compare the two products\\n3. Compare the two products by their features\\n4. Compare the two products by their specifications\\n5. Compare the two products by their performance'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# before finetuning we try the model prediction\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=model.device)\n",
    "human = \"human: {}\\n{}\".format(\"List five steps for comparing two products.\", \"\").strip() + \"\\n\\nAssistant: \"\n",
    "pipe(human, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'human: List five steps for comparing two products.\\n\\nAssistant: 1. Identify the main difference between the two products\\n2. Compare the two products\\n3. Evaluate the performance of the two products\\n4. Compare the two products\\n5. Evaluate the overall performance of the two products'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after finetuning, we get the prediction\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=model.device)\n",
    "human = \"human: {}\\n{}\".format(\"List five steps for comparing two products.\", \"\").strip() + \"\\n\\nAssistant: \"\n",
    "pipe(human, max_length=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using bitfit we can reduce largely the training parameters so to decrease memory usage. Bu this method has limited capacity for applications due to the fact that the full model should be saved every time, which still require a lot of saving space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser",
   "language": "python",
   "name": "diffuser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
