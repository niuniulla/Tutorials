{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this neotebook it will:\n",
    "\n",
    "    I. explain the similarity problem.\n",
    "    II. Model\n",
    "    III. Realization\n",
    "    IV. Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. definition\n",
    "\n",
    "The text Match handle the problems involving the texts relationships such as similarity, matching.\n",
    "It can be applied to conversation, text search, question-answering, compute similarity, etc.\n",
    "The multi-choice can also be considered as text match.\n",
    "\n",
    "In this context, we concentrate on the match of 2 texts.\n",
    "When we talk about the similarity here, we refer to semantic similarity.\n",
    "\n",
    "Example:\n",
    "\n",
    "| text1  |  text2 | similar |\n",
    "|----------|:-------|:-------:|\n",
    "| the cat ate the mouse | the mouse ate the cat food | 0 |\n",
    "| I like the product | It is not a bad product | 1 |\n",
    "| The film came out yesterday| The ticket is expensive | 0 |\n",
    "| He will come tomorrow no matter what | Nothing will stop him to come tomorrow | 1 |\n",
    "\n",
    "### 2. data processing\n",
    "\n",
    "    ___________________________________________________________\n",
    "    |CLS|       sentence1       |SEP|      sentence2      |SEP|\n",
    "    -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is the same as the classification model used in basics with the output of dimension 1.\n",
    "\n",
    "Since the output dim is 1, the prediction is score based, we consider similar when output score > 0.54, else not similar.\n",
    "\n",
    "in the code:\n",
    "\n",
    "```python\n",
    "if self.num_labels == 1:\n",
    "    self.config.problem_type = \"regression\"\n",
    "```\n",
    "\n",
    "So since our num_labels is 1, the type of the model becomes regression. This can be checked using: model.config.problem_type after doawloading the model.\n",
    "\n",
    "```python\n",
    "if self.config.problem_type == \"regression\":\n",
    "    loss_fct = MSELoss()\n",
    "    if self.num_labels == 1:\n",
    "        loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "```\n",
    "\n",
    "The loss function is MSELoss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set the gpu to use\n",
    "# Since I have 2 GPUs and I only want to use one, I need to run this.\n",
    "# Should be run the first\n",
    "# skip this if you don't need.\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # or \"0,1\" for multiple GPUs\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defin repos for data and model\n",
    "\n",
    "# data\n",
    "\n",
    "ckp_data = \"PiC/phrase_similarity\"\n",
    "\n",
    "# model\n",
    "\n",
    "ckp = \"google-bert/bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 11:04:36.874860: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-21 11:04:36.874912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-21 11:04:36.877838: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-21 11:04:36.893172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 11:04:39.135428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['phrase1', 'phrase2', 'sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 7004\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['phrase1', 'phrase2', 'sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['phrase1', 'phrase2', 'sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(ckp_data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phrase1': 'newly formed camp',\n",
       " 'phrase2': 'recently made encampment',\n",
       " 'sentence1': 'newly formed camp is released from the membrane and diffuses across the intracellular space where it serves to activate pka.',\n",
       " 'sentence2': 'recently made encampment is released from the membrane and diffuses across the intracellular space where it serves to activate pka.',\n",
       " 'label': 0,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show one data\n",
    "\n",
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split data\n",
    "\n",
    "skip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckp)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing function\n",
    "\n",
    "def process(samples):\n",
    "\n",
    "    toks = tokenizer(samples[\"sentence1\"], samples[\"sentence2\"], max_length=128, truncation=True)\n",
    "    toks[\"labels\"] = [float(l) for l in samples[\"label\"]]\n",
    "\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7189dd3bcb412ba857a567bfbe8978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3551a933e74aee9b9a42d4d8339917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2479a41886484a9e846a7c7cec30f62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 7004\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "tokenized_data = data.map(process, batched=True, remove_columns=data[\"train\"].column_names)\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101,\n",
       "  3602,\n",
       "  2008,\n",
       "  2755,\n",
       "  1015,\n",
       "  2515,\n",
       "  2025,\n",
       "  7868,\n",
       "  2151,\n",
       "  3327,\n",
       "  3252,\n",
       "  2006,\n",
       "  1996,\n",
       "  2275,\n",
       "  5675,\n",
       "  1035,\n",
       "  3515,\n",
       "  1012,\n",
       "  102,\n",
       "  3602,\n",
       "  2008,\n",
       "  2755,\n",
       "  1015,\n",
       "  2515,\n",
       "  2025,\n",
       "  7868,\n",
       "  2151,\n",
       "  3563,\n",
       "  3968,\n",
       "  23664,\n",
       "  2006,\n",
       "  1996,\n",
       "  2275,\n",
       "  5675,\n",
       "  1035,\n",
       "  3515,\n",
       "  1012,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some data\n",
    "\n",
    "tokenized_data[\"train\"][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(ckp, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.problem_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. define metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "acc_func = evaluate.load(\"accuracy\")\n",
    "f1_func = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(pred):\n",
    "\n",
    "    preds, refs = pred\n",
    "    preds = [int(p > 0.5) for p in preds]\n",
    "    refs = [int(l > 0.5) for l in refs]\n",
    "    \n",
    "    acc = acc_func.compute(predictions=preds, references=refs)\n",
    "    f1 = f1_func.compute(predictions=preds, references=refs)\n",
    "\n",
    "    acc.update(f1)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. train args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Qingyi/.local/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "        output_dir=\"../tmp/checkpoints\",\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=128,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. train + eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78588/56354459.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  preds = [int(p > 0.5) for p in preds]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3240305185317993,\n",
       " 'eval_accuracy': 0.5,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_runtime': 3.3586,\n",
       " 'eval_samples_per_second': 595.485,\n",
       " 'eval_steps_per_second': 4.764}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [330/330 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.200395</td>\n",
       "      <td>0.716500</td>\n",
       "      <td>0.729097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.227135</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.715800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.240205</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.718143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78588/56354459.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  preds = [int(p > 0.5) for p in preds]\n",
      "/tmp/ipykernel_78588/56354459.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  preds = [int(p > 0.5) for p in preds]\n",
      "/tmp/ipykernel_78588/56354459.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  preds = [int(p > 0.5) for p in preds]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=330, training_loss=0.10457922545346347, metrics={'train_runtime': 100.8683, 'train_samples_per_second': 208.311, 'train_steps_per_second': 3.272, 'total_flos': 919141441454256.0, 'train_loss': 0.10457922545346347, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 01:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78588/56354459.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  preds = [int(p > 0.5) for p in preds]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20629166066646576,\n",
       " 'eval_accuracy': 0.7085,\n",
       " 'eval_f1': 0.7329363261566652,\n",
       " 'eval_runtime': 2.621,\n",
       " 'eval_samples_per_second': 763.073,\n",
       " 'eval_steps_per_second': 6.105,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_data[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'LABEL_0', 'score': 0.1934397965669632}\n",
      "CPU times: user 36.6 ms, sys: 22.3 ms, total: 58.9 ms\n",
      "Wall time: 53.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'not similar'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# the label returned by pipe is meaningless in this case, since it always return 0\n",
    "# So we use the score which is the output scalar of the model\n",
    "\n",
    "out = pipe({\"text\": \"This place is not what I want.\", \"text_pair\": \"The weather is hot.\"}, function_to_apply=\"none\")\n",
    "print(out)\n",
    "pred = \"similar\" if out[\"score\"] > 0.5 else \"not similar\"\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'LABEL_0', 1: 'LABEL_1'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref:  0\n",
      "pred:  0.008944655768573284\n",
      "ref:  0\n",
      "pred:  0.11162159591913223\n",
      "ref:  1\n",
      "pred:  0.2571737766265869\n",
      "ref:  0\n",
      "pred:  0.3957631289958954\n",
      "ref:  0\n",
      "pred:  0.14410561323165894\n",
      "ref:  0\n",
      "pred:  0.08695762604475021\n",
      "ref:  0\n",
      "pred:  0.023133572190999985\n",
      "ref:  1\n",
      "pred:  0.8889474272727966\n",
      "ref:  1\n",
      "pred:  0.0772826075553894\n",
      "ref:  0\n",
      "pred:  0.32186418771743774\n",
      "ref:  0\n",
      "pred:  0.06406279653310776\n",
      "ref:  0\n",
      "pred:  0.035871099680662155\n",
      "ref:  0\n",
      "pred:  0.8888132572174072\n",
      "ref:  0\n",
      "pred:  0.14307324588298798\n",
      "ref:  0\n",
      "pred:  0.1918620616197586\n",
      "ref:  1\n",
      "pred:  0.8433682918548584\n",
      "ref:  1\n",
      "pred:  0.5614240765571594\n",
      "ref:  0\n",
      "pred:  0.06535700708627701\n",
      "ref:  0\n",
      "pred:  0.28326693177223206\n",
      "ref:  0\n",
      "pred:  0.9595742225646973\n"
     ]
    }
   ],
   "source": [
    "subset = \"test\"\n",
    "for i in range(0,20):\n",
    "    print(\"ref: \", data[subset][i][\"label\"])\n",
    "    out = pipe({\"text\": data[subset][i][\"sentence1\"], \"text_pair\": data[subset][i][\"sentence2\"]}, function_to_apply=\"none\")\n",
    "    print(\"pred: \", out[\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Problem\n",
    "\n",
    "If we have a lot of texts to match, it will be inefficient if use the same technique as above: take a pair of texts and test their similarity.\n",
    "\n",
    "eg. if we have a text to be matched against 1M texts database. We see as using pipeline of HF, it takes some 50ms to infer. This will take 1M * 50ms ~ 50000s ~ 14h."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Solution\n",
    "\n",
    "So we can use another atrategy for this kind of problem: embed the candidate texts and save them. When there is a text to match, we can just find the closest candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. HF solution\n",
    "\n",
    "1 - 3 steps unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740f106588014ce9b05088aa9c49302b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7004 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012ab469c4e643c3a607bda52c1e5449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ce0609053a4cfa9ff5b57c299f7a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 7004\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(samples):\n",
    "\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for ind in range(len(samples[\"label\"])):\n",
    "        sentences.append(samples[\"sentence1\"][ind])\n",
    "        sentences.append(samples[\"sentence2\"][ind])\n",
    "        labels.append(1.0 if samples[\"label\"][ind] == 1 else -1.0) # this is for cos loss for similarity\n",
    "\n",
    "    toks = tokenizer(sentences, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    toks = {k: [v[i:i+2] for i in range(0, len(v), 2)] for k, v in toks.items()}\n",
    "    toks[\"labels\"] = labels\n",
    "\n",
    "    return toks\n",
    "\n",
    "tokenized_data = data.map(process, batched=True, remove_columns=data[\"train\"].column_names)\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 4397, 2719, 3409, 2003, 2207, 2013, 1996, 10804, 1998, 28105, 2015, 2408, 1996, 26721, 16882, 2686, 2073, 2009, 4240, 2000, 20544, 1052, 2912, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3728, 2081, 4372, 26468, 3672, 2003, 2207, 2013, 1996, 10804, 1998, 28105, 2015, 2408, 1996, 26721, 16882, 2686, 2073, 2009, 4240, 2000, 20544, 1052, 2912, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': -1.0}\n"
     ]
    }
   ],
   "source": [
    "# show data\n",
    "\n",
    "print(tokenized_data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. model\n",
    "\n",
    "In this step, instead of load only a model, we have to define a customized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertPreTrainedModel, BertModel\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch.nn import CosineSimilarity, CosineEmbeddingLoss\n",
    "\n",
    "# we redefine the model since there is no ready-to-use model for this problem.\n",
    "# precisely, no model can handle our new data dim is [batchn 2, seq_len].\n",
    "# The reference is the BertForSequenceClassification model to produce the below code\n",
    "\n",
    "class EmbedModel(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.post_init()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        # get sentence1 and sentence2\n",
    "        s1_input_ids, s2_input_ids = input_ids[:, 0], input_ids[:, 1]\n",
    "        s1_attention_mask, s2_attention_mask = attention_mask[:, 0], attention_mask[:, 1]\n",
    "        s1_token_type_ids, s2_token_type_ids = token_type_ids[:, 0], token_type_ids[:, 1]\n",
    "\n",
    "\n",
    "        s1_outputs = self.bert(\n",
    "            s1_input_ids,\n",
    "            attention_mask=s1_attention_mask,\n",
    "            token_type_ids=s1_token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        s1_pooled_output = s1_outputs[1] # [batch, hidden]\n",
    "\n",
    "        s2_outputs = self.bert(\n",
    "            s2_input_ids,\n",
    "            attention_mask=s2_attention_mask,\n",
    "            token_type_ids=s2_token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        s2_pooled_output = s2_outputs[1] # [batch, hidden]\n",
    "\n",
    "        # compute similarity of the hiddens\n",
    "        simi = CosineSimilarity()(s1_pooled_output, s2_pooled_output)\n",
    "\n",
    "        # loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CosineEmbeddingLoss(0.3)\n",
    "            loss = loss_fct(s1_pooled_output, s2_pooled_output, labels)\n",
    "\n",
    "        output = (simi,)\n",
    "        return ((loss,) + output) if loss is not None else output # should return first loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct model\n",
    "\n",
    "model = EmbedModel.from_pretrained(ckp)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "acc_func = evaluate.load(\"accuracy\")\n",
    "f1_func = evaluate.load(\"f1\")\n",
    "\n",
    "def metric(pred):\n",
    "\n",
    "    preds, refs = pred\n",
    "    preds = [int(p > 0.7) for p in preds]\n",
    "    refs = [int(l > 0) for l in refs] # should convert back to [0,1] instead of [1,-1]\n",
    "\n",
    "    acc = acc_func.compute(predictions=preds, references=refs)\n",
    "    f1 = f1_func.compute(predictions=preds, references=refs)\n",
    "\n",
    "    acc.update(f1)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. train args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Qingyi/.local/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "args = TrainingArguments(\n",
    "        output_dir=\"./checkpoints\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"validation\"],\n",
    "    compute_metrics=metric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. train + eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='657' max='657' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [657/657 04:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.276205</td>\n",
       "      <td>0.623000</td>\n",
       "      <td>0.694242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.282983</td>\n",
       "      <td>0.637000</td>\n",
       "      <td>0.692633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.280566</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.698145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=657, training_loss=0.11748833834127023, metrics={'train_runtime': 241.5772, 'train_samples_per_second': 86.978, 'train_steps_per_second': 2.72, 'total_flos': 2764195109535744.0, 'train_loss': 0.11748833834127023, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityPipeline:\n",
    "\n",
    "    def __init__(self, model, tokenizer) -> None:\n",
    "        self.model = model.bert\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.device\n",
    "\n",
    "    def preprocess(self, senA, senB):\n",
    "        return self.tokenizer([senA, senB], max_length=128, truncation=True, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        return self.model(**inputs)[1]  # [2, 768]\n",
    "\n",
    "    def postprocess(self, logits):\n",
    "        cos = CosineSimilarity()(logits[None, 0, :], logits[None, 1, :]).squeeze().cpu().item()\n",
    "        return cos\n",
    "\n",
    "    def __call__(self, senA, senB, return_vector=False):\n",
    "        inputs = self.preprocess(senA, senB)\n",
    "        logits = self.predict(inputs)\n",
    "        result = self.postprocess(logits)\n",
    "        if return_vector:\n",
    "            return result, logits\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = SimilarityPipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5793790817260742,\n",
       " tensor([[ 0.9772,  0.9492,  1.0000,  ...,  1.0000,  0.9650, -0.9397],\n",
       "         [-0.9744, -0.5174,  0.7518,  ...,  0.1605, -0.6033,  0.9713]],\n",
       "        device='cuda:0', grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(data[\"test\"][0][\"sentence1\"], data[\"test\"][0][\"sentence2\"], return_vector=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Doc:\n",
    " - https://www.newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser",
   "language": "python",
   "name": "diffuser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
