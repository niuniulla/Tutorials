{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# half precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of f32, we can use f16, which is half of the default precision, where comes the name half precision.\n",
    "For half precision, the smallest positive value is ~5.9e-8 and the largest value is ~65504 (https://devblogs.microsoft.com/dotnet/introducing-the-half-type.)\n",
    "\n",
    "Using half-precision, we can save the memory usage.\n",
    "But, we may have problems such as overflow, rounding (if newer GPU, use bf16).\n",
    "\n",
    "So, to use it: \n",
    " * option1: model = model.half()\n",
    " * option2: XXXmodel.from_pretrained(ckp, torch_type=torch.half)\n",
    "\n",
    "The option2 will require less resources, since option1 still needs full precision resources to load the model, and then convert it to half precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6e-8 is:  5.960464477539063e-08\n",
      "1e-8 is:  0.0\n"
     ]
    }
   ],
   "source": [
    "# to illustrate problem of overflow\n",
    "# since the limit of half precision is ~5.9e-8, any value smaller then this value will become 0\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"6e-8 is: \", torch.tensor(6e-8).half().item())\n",
    "print(\"1e-8 is: \", torch.tensor(1e-8).half().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. LlaMA2\n",
    "\n",
    " - Meta opensource pre-trained model\n",
    " - auto-regressive model\n",
    " - sizes: 7B, 13B, 70B\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to set the gpu to use\n",
    "# Since I have 2 GPUs and I only want to use one, I need to run this\n",
    "# Should be run the first\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # or \"0,1\" for multiple GPUs\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 10:37:58.220885: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-26 10:37:58.220946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-26 10:37:58.223924: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-26 10:37:58.237042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 10:38:00.356777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "ckp_data = \"yahma/alpaca-cleaned\"\n",
    "ckp = \"NousResearch/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "data = load_dataset(ckp_data, split=\"train[:1000]\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='NousResearch/Llama-2-7b-chat-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t32000: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load tokenizer\n",
    "\n",
    "# LLama tokenizer, the default padding_side is \"left\".\n",
    "# If we leave this option to default, when training, the loss will be 0 after 1 or 2 steps.\n",
    "# This is because that the actual data contributing to the loss are on the right (after \"assistant\" key word).\n",
    "\n",
    "# So we have to set this option to \"right\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckp)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "\n",
    "def process(sample):\n",
    "\n",
    "    MAX_LEN = 256\n",
    "\n",
    "    human = tokenizer(\"Human: \" + \"\\n\".join([sample[\"instruction\"], sample[\"input\"]]).strip() + \"\\n\\nAssistant: \", add_special_tokens=False)\n",
    "    \n",
    "    # if we set the add_special_tokens to true, it will add the sos also that we don't want\n",
    "    # if we add the eos directly to the sample's output string, we should add a space between them\n",
    "    # otherwise, the last word will become \"{word}eos\", which is different from \"{word} eos\".\n",
    "    # So the simplest way is to add the eso directly to the input_ids as shown below.\n",
    "    \n",
    "    ml = tokenizer(sample[\"output\"], add_special_tokens=False)\n",
    "\n",
    "    input_ids = human[\"input_ids\"] + ml[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "    attention_mask = human[\"attention_mask\"] + ml[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(human[\"input_ids\"]) + ml[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "\n",
    "    if len(input_ids) > MAX_LEN:\n",
    "\n",
    "        input_ids = input_ids[:MAX_LEN]\n",
    "        attention_mask = attention_mask[:MAX_LEN]\n",
    "        labels = labels[:MAX_LEN]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize dataset\n",
    "\n",
    "tokenized_data = data.map(process, remove_columns=data.column_names)\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What are the three primary colors?\\n\\nAssistant:  The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).</s>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we notice that the tokenizer added some special tokens: eos\n",
    "\n",
    "tokenizer.decode(tokenized_data[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12968, 29901, 1724, 526, 278, 2211, 7601, 11955, 29973, 13, 13, 7900, 22137, 29901, 29871, 450, 2211, 7601, 11955, 526, 2654, 29892, 7254, 29892, 322, 13328, 29889, 4525, 11955, 526, 2000, 7601, 1363, 896, 2609, 367, 2825, 491, 24907, 916, 11955, 322, 599, 916, 11955, 508, 367, 1754, 491, 29299, 963, 297, 5164, 12098, 1080, 29889, 512, 278, 788, 3321, 2927, 1788, 29892, 1304, 363, 3578, 29892, 278, 7601, 11955, 526, 2654, 29892, 7933, 29892, 322, 7254, 313, 28212, 467, 2]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_data[1][\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9466f72b7540fab4b399512bd60fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model\n",
    "# after loading, 13B of GPU memory was taken\n",
    "\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(ckp, low_cpu_mem_usage=True, \n",
    "                                             torch_dtype=torch.half, \n",
    "                                             device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the type of the model\n",
    "\n",
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.float16\n",
      "model.layers.0.self_attn.q_proj.weight torch.float16\n",
      "model.layers.0.self_attn.k_proj.weight torch.float16\n",
      "model.layers.0.self_attn.v_proj.weight torch.float16\n",
      "model.layers.0.self_attn.o_proj.weight torch.float16\n",
      "model.layers.0.mlp.gate_proj.weight torch.float16\n",
      "model.layers.0.mlp.up_proj.weight torch.float16\n",
      "model.layers.0.mlp.down_proj.weight torch.float16\n",
      "model.layers.0.input_layernorm.weight torch.float16\n",
      "model.layers.0.post_attention_layernorm.weight torch.float16\n",
      "model.layers.1.self_attn.q_proj.weight torch.float16\n",
      "model.layers.1.self_attn.k_proj.weight torch.float16\n",
      "model.layers.1.self_attn.v_proj.weight torch.float16\n",
      "model.layers.1.self_attn.o_proj.weight torch.float16\n",
      "model.layers.1.mlp.gate_proj.weight torch.float16\n",
      "model.layers.1.mlp.up_proj.weight torch.float16\n",
      "model.layers.1.mlp.down_proj.weight torch.float16\n",
      "model.layers.1.input_layernorm.weight torch.float16\n",
      "model.layers.1.post_attention_layernorm.weight torch.float16\n",
      "model.layers.2.self_attn.q_proj.weight torch.float16\n",
      "model.layers.2.self_attn.k_proj.weight torch.float16\n",
      "model.layers.2.self_attn.v_proj.weight torch.float16\n",
      "model.layers.2.self_attn.o_proj.weight torch.float16\n",
      "model.layers.2.mlp.gate_proj.weight torch.float16\n",
      "model.layers.2.mlp.up_proj.weight torch.float16\n",
      "model.layers.2.mlp.down_proj.weight torch.float16\n",
      "model.layers.2.input_layernorm.weight torch.float16\n",
      "model.layers.2.post_attention_layernorm.weight torch.float16\n",
      "model.layers.3.self_attn.q_proj.weight torch.float16\n",
      "model.layers.3.self_attn.k_proj.weight torch.float16\n",
      "model.layers.3.self_attn.v_proj.weight torch.float16\n",
      "model.layers.3.self_attn.o_proj.weight torch.float16\n",
      "model.layers.3.mlp.gate_proj.weight torch.float16\n",
      "model.layers.3.mlp.up_proj.weight torch.float16\n",
      "model.layers.3.mlp.down_proj.weight torch.float16\n",
      "model.layers.3.input_layernorm.weight torch.float16\n",
      "model.layers.3.post_attention_layernorm.weight torch.float16\n",
      "model.layers.4.self_attn.q_proj.weight torch.float16\n",
      "model.layers.4.self_attn.k_proj.weight torch.float16\n",
      "model.layers.4.self_attn.v_proj.weight torch.float16\n",
      "model.layers.4.self_attn.o_proj.weight torch.float16\n",
      "model.layers.4.mlp.gate_proj.weight torch.float16\n",
      "model.layers.4.mlp.up_proj.weight torch.float16\n",
      "model.layers.4.mlp.down_proj.weight torch.float16\n",
      "model.layers.4.input_layernorm.weight torch.float16\n",
      "model.layers.4.post_attention_layernorm.weight torch.float16\n",
      "model.layers.5.self_attn.q_proj.weight torch.float16\n",
      "model.layers.5.self_attn.k_proj.weight torch.float16\n",
      "model.layers.5.self_attn.v_proj.weight torch.float16\n",
      "model.layers.5.self_attn.o_proj.weight torch.float16\n",
      "model.layers.5.mlp.gate_proj.weight torch.float16\n",
      "model.layers.5.mlp.up_proj.weight torch.float16\n",
      "model.layers.5.mlp.down_proj.weight torch.float16\n",
      "model.layers.5.input_layernorm.weight torch.float16\n",
      "model.layers.5.post_attention_layernorm.weight torch.float16\n",
      "model.layers.6.self_attn.q_proj.weight torch.float16\n",
      "model.layers.6.self_attn.k_proj.weight torch.float16\n",
      "model.layers.6.self_attn.v_proj.weight torch.float16\n",
      "model.layers.6.self_attn.o_proj.weight torch.float16\n",
      "model.layers.6.mlp.gate_proj.weight torch.float16\n",
      "model.layers.6.mlp.up_proj.weight torch.float16\n",
      "model.layers.6.mlp.down_proj.weight torch.float16\n",
      "model.layers.6.input_layernorm.weight torch.float16\n",
      "model.layers.6.post_attention_layernorm.weight torch.float16\n",
      "model.layers.7.self_attn.q_proj.weight torch.float16\n",
      "model.layers.7.self_attn.k_proj.weight torch.float16\n",
      "model.layers.7.self_attn.v_proj.weight torch.float16\n",
      "model.layers.7.self_attn.o_proj.weight torch.float16\n",
      "model.layers.7.mlp.gate_proj.weight torch.float16\n",
      "model.layers.7.mlp.up_proj.weight torch.float16\n",
      "model.layers.7.mlp.down_proj.weight torch.float16\n",
      "model.layers.7.input_layernorm.weight torch.float16\n",
      "model.layers.7.post_attention_layernorm.weight torch.float16\n",
      "model.layers.8.self_attn.q_proj.weight torch.float16\n",
      "model.layers.8.self_attn.k_proj.weight torch.float16\n",
      "model.layers.8.self_attn.v_proj.weight torch.float16\n",
      "model.layers.8.self_attn.o_proj.weight torch.float16\n",
      "model.layers.8.mlp.gate_proj.weight torch.float16\n",
      "model.layers.8.mlp.up_proj.weight torch.float16\n",
      "model.layers.8.mlp.down_proj.weight torch.float16\n",
      "model.layers.8.input_layernorm.weight torch.float16\n",
      "model.layers.8.post_attention_layernorm.weight torch.float16\n",
      "model.layers.9.self_attn.q_proj.weight torch.float16\n",
      "model.layers.9.self_attn.k_proj.weight torch.float16\n",
      "model.layers.9.self_attn.v_proj.weight torch.float16\n",
      "model.layers.9.self_attn.o_proj.weight torch.float16\n",
      "model.layers.9.mlp.gate_proj.weight torch.float16\n",
      "model.layers.9.mlp.up_proj.weight torch.float16\n",
      "model.layers.9.mlp.down_proj.weight torch.float16\n",
      "model.layers.9.input_layernorm.weight torch.float16\n",
      "model.layers.9.post_attention_layernorm.weight torch.float16\n",
      "model.layers.10.self_attn.q_proj.weight torch.float16\n",
      "model.layers.10.self_attn.k_proj.weight torch.float16\n",
      "model.layers.10.self_attn.v_proj.weight torch.float16\n",
      "model.layers.10.self_attn.o_proj.weight torch.float16\n",
      "model.layers.10.mlp.gate_proj.weight torch.float16\n",
      "model.layers.10.mlp.up_proj.weight torch.float16\n",
      "model.layers.10.mlp.down_proj.weight torch.float16\n",
      "model.layers.10.input_layernorm.weight torch.float16\n",
      "model.layers.10.post_attention_layernorm.weight torch.float16\n",
      "model.layers.11.self_attn.q_proj.weight torch.float16\n",
      "model.layers.11.self_attn.k_proj.weight torch.float16\n",
      "model.layers.11.self_attn.v_proj.weight torch.float16\n",
      "model.layers.11.self_attn.o_proj.weight torch.float16\n",
      "model.layers.11.mlp.gate_proj.weight torch.float16\n",
      "model.layers.11.mlp.up_proj.weight torch.float16\n",
      "model.layers.11.mlp.down_proj.weight torch.float16\n",
      "model.layers.11.input_layernorm.weight torch.float16\n",
      "model.layers.11.post_attention_layernorm.weight torch.float16\n",
      "model.layers.12.self_attn.q_proj.weight torch.float16\n",
      "model.layers.12.self_attn.k_proj.weight torch.float16\n",
      "model.layers.12.self_attn.v_proj.weight torch.float16\n",
      "model.layers.12.self_attn.o_proj.weight torch.float16\n",
      "model.layers.12.mlp.gate_proj.weight torch.float16\n",
      "model.layers.12.mlp.up_proj.weight torch.float16\n",
      "model.layers.12.mlp.down_proj.weight torch.float16\n",
      "model.layers.12.input_layernorm.weight torch.float16\n",
      "model.layers.12.post_attention_layernorm.weight torch.float16\n",
      "model.layers.13.self_attn.q_proj.weight torch.float16\n",
      "model.layers.13.self_attn.k_proj.weight torch.float16\n",
      "model.layers.13.self_attn.v_proj.weight torch.float16\n",
      "model.layers.13.self_attn.o_proj.weight torch.float16\n",
      "model.layers.13.mlp.gate_proj.weight torch.float16\n",
      "model.layers.13.mlp.up_proj.weight torch.float16\n",
      "model.layers.13.mlp.down_proj.weight torch.float16\n",
      "model.layers.13.input_layernorm.weight torch.float16\n",
      "model.layers.13.post_attention_layernorm.weight torch.float16\n",
      "model.layers.14.self_attn.q_proj.weight torch.float16\n",
      "model.layers.14.self_attn.k_proj.weight torch.float16\n",
      "model.layers.14.self_attn.v_proj.weight torch.float16\n",
      "model.layers.14.self_attn.o_proj.weight torch.float16\n",
      "model.layers.14.mlp.gate_proj.weight torch.float16\n",
      "model.layers.14.mlp.up_proj.weight torch.float16\n",
      "model.layers.14.mlp.down_proj.weight torch.float16\n",
      "model.layers.14.input_layernorm.weight torch.float16\n",
      "model.layers.14.post_attention_layernorm.weight torch.float16\n",
      "model.layers.15.self_attn.q_proj.weight torch.float16\n",
      "model.layers.15.self_attn.k_proj.weight torch.float16\n",
      "model.layers.15.self_attn.v_proj.weight torch.float16\n",
      "model.layers.15.self_attn.o_proj.weight torch.float16\n",
      "model.layers.15.mlp.gate_proj.weight torch.float16\n",
      "model.layers.15.mlp.up_proj.weight torch.float16\n",
      "model.layers.15.mlp.down_proj.weight torch.float16\n",
      "model.layers.15.input_layernorm.weight torch.float16\n",
      "model.layers.15.post_attention_layernorm.weight torch.float16\n",
      "model.layers.16.self_attn.q_proj.weight torch.float16\n",
      "model.layers.16.self_attn.k_proj.weight torch.float16\n",
      "model.layers.16.self_attn.v_proj.weight torch.float16\n",
      "model.layers.16.self_attn.o_proj.weight torch.float16\n",
      "model.layers.16.mlp.gate_proj.weight torch.float16\n",
      "model.layers.16.mlp.up_proj.weight torch.float16\n",
      "model.layers.16.mlp.down_proj.weight torch.float16\n",
      "model.layers.16.input_layernorm.weight torch.float16\n",
      "model.layers.16.post_attention_layernorm.weight torch.float16\n",
      "model.layers.17.self_attn.q_proj.weight torch.float16\n",
      "model.layers.17.self_attn.k_proj.weight torch.float16\n",
      "model.layers.17.self_attn.v_proj.weight torch.float16\n",
      "model.layers.17.self_attn.o_proj.weight torch.float16\n",
      "model.layers.17.mlp.gate_proj.weight torch.float16\n",
      "model.layers.17.mlp.up_proj.weight torch.float16\n",
      "model.layers.17.mlp.down_proj.weight torch.float16\n",
      "model.layers.17.input_layernorm.weight torch.float16\n",
      "model.layers.17.post_attention_layernorm.weight torch.float16\n",
      "model.layers.18.self_attn.q_proj.weight torch.float16\n",
      "model.layers.18.self_attn.k_proj.weight torch.float16\n",
      "model.layers.18.self_attn.v_proj.weight torch.float16\n",
      "model.layers.18.self_attn.o_proj.weight torch.float16\n",
      "model.layers.18.mlp.gate_proj.weight torch.float16\n",
      "model.layers.18.mlp.up_proj.weight torch.float16\n",
      "model.layers.18.mlp.down_proj.weight torch.float16\n",
      "model.layers.18.input_layernorm.weight torch.float16\n",
      "model.layers.18.post_attention_layernorm.weight torch.float16\n",
      "model.layers.19.self_attn.q_proj.weight torch.float16\n",
      "model.layers.19.self_attn.k_proj.weight torch.float16\n",
      "model.layers.19.self_attn.v_proj.weight torch.float16\n",
      "model.layers.19.self_attn.o_proj.weight torch.float16\n",
      "model.layers.19.mlp.gate_proj.weight torch.float16\n",
      "model.layers.19.mlp.up_proj.weight torch.float16\n",
      "model.layers.19.mlp.down_proj.weight torch.float16\n",
      "model.layers.19.input_layernorm.weight torch.float16\n",
      "model.layers.19.post_attention_layernorm.weight torch.float16\n",
      "model.layers.20.self_attn.q_proj.weight torch.float16\n",
      "model.layers.20.self_attn.k_proj.weight torch.float16\n",
      "model.layers.20.self_attn.v_proj.weight torch.float16\n",
      "model.layers.20.self_attn.o_proj.weight torch.float16\n",
      "model.layers.20.mlp.gate_proj.weight torch.float16\n",
      "model.layers.20.mlp.up_proj.weight torch.float16\n",
      "model.layers.20.mlp.down_proj.weight torch.float16\n",
      "model.layers.20.input_layernorm.weight torch.float16\n",
      "model.layers.20.post_attention_layernorm.weight torch.float16\n",
      "model.layers.21.self_attn.q_proj.weight torch.float16\n",
      "model.layers.21.self_attn.k_proj.weight torch.float16\n",
      "model.layers.21.self_attn.v_proj.weight torch.float16\n",
      "model.layers.21.self_attn.o_proj.weight torch.float16\n",
      "model.layers.21.mlp.gate_proj.weight torch.float16\n",
      "model.layers.21.mlp.up_proj.weight torch.float16\n",
      "model.layers.21.mlp.down_proj.weight torch.float16\n",
      "model.layers.21.input_layernorm.weight torch.float16\n",
      "model.layers.21.post_attention_layernorm.weight torch.float16\n",
      "model.layers.22.self_attn.q_proj.weight torch.float16\n",
      "model.layers.22.self_attn.k_proj.weight torch.float16\n",
      "model.layers.22.self_attn.v_proj.weight torch.float16\n",
      "model.layers.22.self_attn.o_proj.weight torch.float16\n",
      "model.layers.22.mlp.gate_proj.weight torch.float16\n",
      "model.layers.22.mlp.up_proj.weight torch.float16\n",
      "model.layers.22.mlp.down_proj.weight torch.float16\n",
      "model.layers.22.input_layernorm.weight torch.float16\n",
      "model.layers.22.post_attention_layernorm.weight torch.float16\n",
      "model.layers.23.self_attn.q_proj.weight torch.float16\n",
      "model.layers.23.self_attn.k_proj.weight torch.float16\n",
      "model.layers.23.self_attn.v_proj.weight torch.float16\n",
      "model.layers.23.self_attn.o_proj.weight torch.float16\n",
      "model.layers.23.mlp.gate_proj.weight torch.float16\n",
      "model.layers.23.mlp.up_proj.weight torch.float16\n",
      "model.layers.23.mlp.down_proj.weight torch.float16\n",
      "model.layers.23.input_layernorm.weight torch.float16\n",
      "model.layers.23.post_attention_layernorm.weight torch.float16\n",
      "model.layers.24.self_attn.q_proj.weight torch.float16\n",
      "model.layers.24.self_attn.k_proj.weight torch.float16\n",
      "model.layers.24.self_attn.v_proj.weight torch.float16\n",
      "model.layers.24.self_attn.o_proj.weight torch.float16\n",
      "model.layers.24.mlp.gate_proj.weight torch.float16\n",
      "model.layers.24.mlp.up_proj.weight torch.float16\n",
      "model.layers.24.mlp.down_proj.weight torch.float16\n",
      "model.layers.24.input_layernorm.weight torch.float16\n",
      "model.layers.24.post_attention_layernorm.weight torch.float16\n",
      "model.layers.25.self_attn.q_proj.weight torch.float16\n",
      "model.layers.25.self_attn.k_proj.weight torch.float16\n",
      "model.layers.25.self_attn.v_proj.weight torch.float16\n",
      "model.layers.25.self_attn.o_proj.weight torch.float16\n",
      "model.layers.25.mlp.gate_proj.weight torch.float16\n",
      "model.layers.25.mlp.up_proj.weight torch.float16\n",
      "model.layers.25.mlp.down_proj.weight torch.float16\n",
      "model.layers.25.input_layernorm.weight torch.float16\n",
      "model.layers.25.post_attention_layernorm.weight torch.float16\n",
      "model.layers.26.self_attn.q_proj.weight torch.float16\n",
      "model.layers.26.self_attn.k_proj.weight torch.float16\n",
      "model.layers.26.self_attn.v_proj.weight torch.float16\n",
      "model.layers.26.self_attn.o_proj.weight torch.float16\n",
      "model.layers.26.mlp.gate_proj.weight torch.float16\n",
      "model.layers.26.mlp.up_proj.weight torch.float16\n",
      "model.layers.26.mlp.down_proj.weight torch.float16\n",
      "model.layers.26.input_layernorm.weight torch.float16\n",
      "model.layers.26.post_attention_layernorm.weight torch.float16\n",
      "model.layers.27.self_attn.q_proj.weight torch.float16\n",
      "model.layers.27.self_attn.k_proj.weight torch.float16\n",
      "model.layers.27.self_attn.v_proj.weight torch.float16\n",
      "model.layers.27.self_attn.o_proj.weight torch.float16\n",
      "model.layers.27.mlp.gate_proj.weight torch.float16\n",
      "model.layers.27.mlp.up_proj.weight torch.float16\n",
      "model.layers.27.mlp.down_proj.weight torch.float16\n",
      "model.layers.27.input_layernorm.weight torch.float16\n",
      "model.layers.27.post_attention_layernorm.weight torch.float16\n",
      "model.layers.28.self_attn.q_proj.weight torch.float16\n",
      "model.layers.28.self_attn.k_proj.weight torch.float16\n",
      "model.layers.28.self_attn.v_proj.weight torch.float16\n",
      "model.layers.28.self_attn.o_proj.weight torch.float16\n",
      "model.layers.28.mlp.gate_proj.weight torch.float16\n",
      "model.layers.28.mlp.up_proj.weight torch.float16\n",
      "model.layers.28.mlp.down_proj.weight torch.float16\n",
      "model.layers.28.input_layernorm.weight torch.float16\n",
      "model.layers.28.post_attention_layernorm.weight torch.float16\n",
      "model.layers.29.self_attn.q_proj.weight torch.float16\n",
      "model.layers.29.self_attn.k_proj.weight torch.float16\n",
      "model.layers.29.self_attn.v_proj.weight torch.float16\n",
      "model.layers.29.self_attn.o_proj.weight torch.float16\n",
      "model.layers.29.mlp.gate_proj.weight torch.float16\n",
      "model.layers.29.mlp.up_proj.weight torch.float16\n",
      "model.layers.29.mlp.down_proj.weight torch.float16\n",
      "model.layers.29.input_layernorm.weight torch.float16\n",
      "model.layers.29.post_attention_layernorm.weight torch.float16\n",
      "model.layers.30.self_attn.q_proj.weight torch.float16\n",
      "model.layers.30.self_attn.k_proj.weight torch.float16\n",
      "model.layers.30.self_attn.v_proj.weight torch.float16\n",
      "model.layers.30.self_attn.o_proj.weight torch.float16\n",
      "model.layers.30.mlp.gate_proj.weight torch.float16\n",
      "model.layers.30.mlp.up_proj.weight torch.float16\n",
      "model.layers.30.mlp.down_proj.weight torch.float16\n",
      "model.layers.30.input_layernorm.weight torch.float16\n",
      "model.layers.30.post_attention_layernorm.weight torch.float16\n",
      "model.layers.31.self_attn.q_proj.weight torch.float16\n",
      "model.layers.31.self_attn.k_proj.weight torch.float16\n",
      "model.layers.31.self_attn.v_proj.weight torch.float16\n",
      "model.layers.31.self_attn.o_proj.weight torch.float16\n",
      "model.layers.31.mlp.gate_proj.weight torch.float16\n",
      "model.layers.31.mlp.up_proj.weight torch.float16\n",
      "model.layers.31.mlp.down_proj.weight torch.float16\n",
      "model.layers.31.input_layernorm.weight torch.float16\n",
      "model.layers.31.post_attention_layernorm.weight torch.float16\n",
      "model.norm.weight torch.float16\n",
      "lm_head.weight torch.float16\n"
     ]
    }
   ],
   "source": [
    "# show more detailed types\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size:  6.738415616 GB\n",
      "total required memory:  134.77 GB\n"
     ]
    }
   ],
   "source": [
    "# get model parameters\n",
    "\n",
    "params = sum(param.numel() for param in model.parameters())\n",
    "print(\"model size: \", params/1e9, \"GB\")\n",
    "print(\"total required memory: \", round(params/1e9 * (1 + 1 + 3) * 4, 2), \"GB\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, inference_mode=False, r=8, target_modules=None, lora_alpha=8, lora_dropout=0.0, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "# config = LoraConfig(task_type=TaskType.CAUSAL_LM, target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"])\n",
    "config = LoraConfig(task_type=TaskType.CAUSAL_LM)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "\n",
    "peft_model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is need if we enable gradient_checkpointing\n",
    "\n",
    "peft_model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.0622\n"
     ]
    }
   ],
   "source": [
    "# show trainable parameter number\n",
    "\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.0.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.0.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.0.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.0.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.0.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.1.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.1.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.1.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.1.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.1.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.2.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.2.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.2.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.2.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.2.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.3.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.3.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.3.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.3.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.3.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.4.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.4.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.4.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.4.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.4.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.5.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.5.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.5.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.5.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.5.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.6.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.6.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.6.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.6.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.6.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.7.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.7.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.7.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.7.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.7.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.8.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.8.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.8.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.8.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.8.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.9.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.9.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.9.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.9.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.9.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.10.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.10.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.10.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.10.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.10.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.11.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.11.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.11.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.11.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.11.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.12.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.12.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.12.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.12.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.12.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.13.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.13.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.13.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.13.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.13.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.14.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.14.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.14.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.14.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.14.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.15.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.15.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.15.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.15.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.15.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.16.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.16.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.16.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.16.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.16.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.16.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.17.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.17.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.17.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.17.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.17.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.17.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.18.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.18.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.18.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.18.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.18.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.18.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.19.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.19.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.19.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.19.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.19.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.19.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.20.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.20.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.20.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.20.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.20.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.20.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.21.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.21.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.21.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.21.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.21.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.21.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.22.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.22.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.22.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.22.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.22.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.22.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.23.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.23.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.23.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.23.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.23.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.23.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.24.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.24.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.24.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.24.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.24.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.24.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.25.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.25.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.25.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.25.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.25.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.25.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.26.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.26.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.26.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.26.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.26.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.26.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.27.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.27.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.27.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.27.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.27.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.27.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.28.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.28.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.28.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.28.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.28.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.28.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.29.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.29.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.29.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.29.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.29.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.29.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.30.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.30.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.30.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.30.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.30.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.30.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.k_proj.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight torch.float16\n",
      "base_model.model.model.layers.31.self_attn.o_proj.weight torch.float16\n",
      "base_model.model.model.layers.31.mlp.gate_proj.weight torch.float16\n",
      "base_model.model.model.layers.31.mlp.up_proj.weight torch.float16\n",
      "base_model.model.model.layers.31.mlp.down_proj.weight torch.float16\n",
      "base_model.model.model.layers.31.input_layernorm.weight torch.float16\n",
      "base_model.model.model.layers.31.post_attention_layernorm.weight torch.float16\n",
      "base_model.model.model.norm.weight torch.float16\n",
      "base_model.model.lm_head.weight torch.float16\n"
     ]
    }
   ],
   "source": [
    "# show type of all layers\n",
    "\n",
    "# make sure all layers are half precision\n",
    "\n",
    "for name, param in peft_model.named_parameters():\n",
    "    print(name, param.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=50,\n",
    "    gradient_checkpointing=True, # need enable_input_require_grads\n",
    "    adam_epsilon=1e-4 # to avoid overflow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model, \n",
    "    args=args,\n",
    "    train_dataset=tokenized_data,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/home/Qingyi/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 05:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.925600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.900400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.004300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.940700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.778600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.901900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.862800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.834200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.850400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.838100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Qingyi/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/Qingyi/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/Qingyi/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.9005191535949707, metrics={'train_runtime': 308.5116, 'train_samples_per_second': 3.241, 'train_steps_per_second': 3.241, 'total_flos': 5855336658862080.0, 'train_loss': 0.9005191535949707, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: hello\\n\\nAssistant:  Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.eval()\n",
    "text = \"hello\"\n",
    "input = tokenizer(\"Human: \" + text + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
    "output = peft_model.generate(**input, max_length=256, eos_token_id=tokenizer.eos_token_id)\n",
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. possible problems with abnormal loss\n",
    "\n",
    " 1) if the loss (batch!=1) explode then becomes 0 after 1 or 2 steps, make sure the tokenizer's padding side is \"right\" instead of \"left\" which is the default value.\n",
    " \n",
    " 2) if the loss still becomes 0 after 1). Check if the all model layers are half precision. If so, change the optimizer's epsilon value (The default epsilon value is 1e-8 and the precision of half precision is ~6e-8. torch.tensor(1e-8).half()=0)\n",
    "to make sure it is greater than 6e-8.\n",
    "\n",
    " 3) use: tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    " 4) if the inference results in unstopped string after eos, check the data processing.\n",
    "\n",
    "\n",
    "Some others points:\n",
    "\n",
    "  - make sure the max_length of tokenizer is long enough for the whole text\n",
    "  - to load the model, add torch.half, otherwise the model will be loaded with full precision\n",
    "  - when using gradient_checkpointing, call peft_model.enable_input_require_grads() first\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffuser",
   "language": "python",
   "name": "diffuser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
